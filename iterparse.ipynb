{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.etree.ElementTree import iterparse\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"lang_list.tsv\", sep=\"\\t\")\n",
    "lang_dict = {k:v for k, v in zip(df[\"Language Code\"], df[\"Language Name (Italian)\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_dict = {}\n",
    "lang_pattern = re.compile(\"=={{-?(.+?)-?}}==\")\n",
    "pos_pattern = re.compile(\"{{-(.*?)-\\|(?:\\|?\\w*)*}}\")\n",
    "morpho_pattern = re.compile(\"(?:{{Pn.*?}}|{{pn.*?}})(?:\\s{1,3})?''(.*?)''\") # a volte ci sono più (o non ci sono) spazi prima della morpho\n",
    "glossa_pattern = re.compile(\"\\[\\[(-?\\w*?-?(?:\\s\\w*?)?)\\]\\]|\\[\\[\\w*?(?:#\\w*)?\\|(.*?)\\]\\]\") # pensare a [[prot-italico]] trattino nel mezzo\n",
    "special_redirect_pattern = re.compile(\"\\[\\[:?\\w+:.*?\\|(.*?)\\]\\]\") # [[:w:.... ... | .... ....]] \n",
    "quote_marks_pattern = re.compile(\"'{2,3}\") # rimuove le virgolette se doppie o triple, notazione di wikipedia per il reindirizzamento\n",
    "ipa_pattern = re.compile(\"{{IPA\\|\\/(.*?)\\/}}\")\n",
    "sill_pattern = re.compile(\"{{-sill-}}\")\n",
    "etim_pattern = re.compile(\"{{-etim-}}\")\n",
    "noetim_pattern = re.compile(\"{{Noetim\\|it}}\")\n",
    "etimlink_pattern = re.compile(\"{{Etim-link\\|(.*?)}}\")\n",
    "vedi_pattern = re.compile(\"{{[Vv]d\\|(.*?)}}\")\n",
    "pron_pattern = re.compile(\"{{-pron-}}\")\n",
    "file_pattern = re.compile(\"\\[\\[File:.*?\\]\\]\")\n",
    "ref_pattern = re.compile(\"<ref.*?>.*?<\\/ref>|<ref.*?\\/>\")\n",
    "lang_pointer_pattern = re.compile(\"{{(\\w+)}}\")\n",
    "all_lemmas = []\n",
    "\n",
    "context = iterparse(\"itwiktionary-20230620-pages-articles.xml\", events=(\"start\", \"end\"))\n",
    "\n",
    "# Get the root element\n",
    "_, root = next(context)\n",
    "\n",
    "# Extract the namespace from the root element\n",
    "NAMESPACE = root.tag.split(\"}\")[0] + \"}\"\n",
    "del context\n",
    "\n",
    "\n",
    "def prepend_ns(s):\n",
    "    return NAMESPACE + s # automate the ns find\n",
    "\n",
    "def remove_list_tokens(line):\n",
    "    if line[0] in [\"*\", \"#\", \":\"]:\n",
    "        return remove_list_tokens(line[1:])\n",
    "    else:\n",
    "        return line\n",
    "\n",
    "def lang_check(line, lemma):\n",
    "    line = line.replace(\" \", \"\") # eliminiamo gli spazi per conformità\n",
    "    match =  re.search(lang_pattern, line) # lingua\n",
    "    if match != None:\n",
    "        lang = match.group(1)\n",
    "        if lang == None:\n",
    "            lang = match.group(2)\n",
    "        if lang == \"it\":\n",
    "            parsed_dict[lemma] = {\"meta\": {\"ipa\": [], \"sill\": [], \"etim\": \"\"}, \"meanings\": {}}\n",
    "            return lang, True\n",
    "        else:\n",
    "            return lang, False\n",
    "    else:\n",
    "        return 0, False\n",
    "    \n",
    "def pron_check(line):\n",
    "    match = re.search(pron_pattern, line)\n",
    "    if match != None:\n",
    "        return True\n",
    "\n",
    "def get_ipa(line, lemma):\n",
    "    match = re.search(ipa_pattern, line) # ipa\n",
    "    if match != None:\n",
    "        ipa = match.group(1)\n",
    "        parsed_dict[lemma][\"meta\"][\"ipa\"].append(ipa)\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def sill_check(line):\n",
    "    \"\"\"To check if the sill token is present in the line\"\"\"\n",
    "    match = re.search(sill_pattern, line) # sill\n",
    "    if match != None:\n",
    "        return True\n",
    "    \n",
    "def get_sill(line, lemma):\n",
    "    if line[0] == \";\":\n",
    "        parsed_dict[lemma][\"meta\"][\"sill\"] = line[1:].replace(\" \", \"\").split(\"|\")\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def pos_check(line):\n",
    "    match = re.search(pos_pattern, line) # pos\n",
    "    if match != None:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def unk_pos(lemma):\n",
    "    pos = \"unk\" # opzione di default (poichè il formato non è consistente)\n",
    "    parsed_dict[lemma][\"meanings\"][pos] = {\"morpho\":\"\", \"glossa\":\"\"}\n",
    "    return pos\n",
    "\n",
    "def check_pos(lemma, line, i_pos, current_pos):\n",
    "    match = re.search(pos_pattern, line) # pos\n",
    "    if match != None:\n",
    "        pos = match.group(1) + f\"_{i_pos}\"\n",
    "        if pos != current_pos and pos != f\"Varie lingue_{i_pos}\":\n",
    "            current_pos = pos\n",
    "            parsed_dict[lemma][\"meanings\"][pos] = {\"morpho\":\"\", \"glossa\":\"\"}\n",
    "            if \"unk\" in parsed_dict[lemma][\"meanings\"]:\n",
    "                del parsed_dict[lemma][\"meanings\"][\"unk\"] # se dopo aver messo unk si trova una pos si elimina unk\n",
    "        return pos\n",
    "    else:\n",
    "        return current_pos\n",
    "    \n",
    "def morpho_check(line, lemma, pos):\n",
    "    match = re.search(morpho_pattern, line) # informazioni morfologiche\n",
    "    if match != None:\n",
    "        morpho = match.group(1).lstrip() # talvolta c'è uno spazio all'inizio\n",
    "        parsed_dict[lemma][\"meanings\"][pos][\"morpho\"] = morpho\n",
    "        return True\n",
    "\n",
    "def etim_check(line):\n",
    "    match = re.search(etim_pattern, line)\n",
    "    if match != None:\n",
    "        return True\n",
    "    \n",
    "def noetim_check(line):\n",
    "    match = re.search(noetim_pattern, line)\n",
    "    if match != None:\n",
    "        return True\n",
    "\n",
    "def get_etim(line, lemma):\n",
    "    line = remove_list_tokens(line)\n",
    "    cleaned_line = re.sub(\"{{Pn}}|{{pn}}\", lemma, line)\n",
    "    cleaned_line = re.sub(ref_pattern, \"\", cleaned_line)\n",
    "    cleaned_line = re.sub(file_pattern, \"\", cleaned_line)\n",
    "    cleaned_line = re.sub(vedi_pattern, lambda m: \"vedi \" + m.group(1).split(\"|\")[1] if \"|\" in m.group(1) else \"vedi \" + m.group(1) , cleaned_line) # {{Vd|Afghanistan#Italiano|Afghanistan}} ---> vedi Afghanistan\n",
    "    cleaned_line = re.sub(etimlink_pattern, lambda m: f\"vedi {m.group(1)}\", cleaned_line)\n",
    "    cleaned_line = re.sub(lang_pointer_pattern, lambda m: lang_dict.get(m.group(1), m.group(0)), cleaned_line)\n",
    "    cleaned_line = re.sub(special_redirect_pattern, r\"\\1\", cleaned_line)\n",
    "    cleaned_line = re.sub(\"{{.*?}}\", \"\", cleaned_line)\n",
    "    cleaned_line = re.sub(glossa_pattern, lambda m: m.group(1) if m.group(2) is None else m.group(2), cleaned_line) # rimuove [[...]] o [[...|...]] tenendo la prima parola\n",
    "    cleaned_line = re.sub(\"\\[\\[\\w.*?\\]\\]\", \"\", cleaned_line)\n",
    "    cleaned_line = re.sub(quote_marks_pattern, \"\", cleaned_line)\n",
    "    cleaned_line = cleaned_line.lstrip()\n",
    "    if parsed_dict[lemma][\"meta\"][\"etim\"] == \"\":\n",
    "        parsed_dict[lemma][\"meta\"][\"etim\"] += cleaned_line\n",
    "    else:\n",
    "        parsed_dict[lemma][\"meta\"][\"etim\"] += \"\\n\"+cleaned_line\n",
    "    \n",
    "def glossa_check(line, lemma, pos):\n",
    "    line = remove_list_tokens(line)\n",
    "    cleaned_line = re.sub(\"{{Pn}}|{{pn}}\", lemma, line)\n",
    "    cleaned_line = re.sub(ref_pattern, \"\", cleaned_line)\n",
    "    cleaned_line = re.sub(file_pattern, \"\", cleaned_line)\n",
    "    cleaned_line = re.sub(vedi_pattern, lambda m: \"vedi \" + m.group(1).split(\"|\")[1] if \"|\" in m.group(1) else \"vedi \" + m.group(1) , cleaned_line) # {{Vd|Afghanistan#Italiano|Afghanistan}} ---> vedi Afghanistan\n",
    "    cleaned_line = re.sub(lang_pointer_pattern, lambda m: lang_dict.get(m.group(1), m.group(0)), cleaned_line)\n",
    "    cleaned_line = re.sub(special_redirect_pattern, r\"\\1\", cleaned_line)\n",
    "    cleaned_line = re.sub(\"{{.*?}}\", \"\", cleaned_line)\n",
    "    cleaned_line = re.sub(glossa_pattern, lambda m: m.group(1) if m.group(2) is None else m.group(2), cleaned_line) # rimuove [[...]] o [[...|...]] tenendo la prima parola\n",
    "    cleaned_line = re.sub(\"\\[\\[\\w.*?\\]\\]\", \"\", cleaned_line)\n",
    "    cleaned_line = re.sub(quote_marks_pattern, \"\", cleaned_line)\n",
    "    cleaned_line = cleaned_line.lstrip()\n",
    "    if parsed_dict[lemma][\"meanings\"][pos][\"glossa\"] == \"\":\n",
    "        parsed_dict[lemma][\"meanings\"][pos][\"glossa\"] += cleaned_line\n",
    "    else:\n",
    "        parsed_dict[lemma][\"meanings\"][pos][\"glossa\"] += \"\\n\"+cleaned_line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    context = iterparse(\"itwiktionary-20230620-pages-articles.xml\", events=(\"start\", \"end\"))\n",
    "\n",
    "    for event, elem in tqdm(context, desc=\"Parsing XML\", unit=\" elements\"):\n",
    "        if event == \"end\":\n",
    "            if prepend_ns(\"page\") == elem.tag:\n",
    "                lemma = elem.find(prepend_ns(\"title\"))\n",
    "                if lemma != None:\n",
    "                    lemma = str(lemma.text)\n",
    "                    if \":\" in lemma or lemma in [\"Pagina principale\", \"Pagina principale/Categorie\"]:\n",
    "                        continue\n",
    "                    all_lemmas.append(lemma)\n",
    "                    revision = elem.find(prepend_ns(\"revision\"))\n",
    "                    glossa = revision.find(prepend_ns(\"text\")).text\n",
    "                    current_pos = \"\"\n",
    "                    lang_found = False\n",
    "                    sill_flag = False\n",
    "                    unk_pos_flag = False\n",
    "                    elenco_flag = False\n",
    "                    etim_flag = False\n",
    "                    pron_flag = False\n",
    "                    i_pos = 0\n",
    "\n",
    "                    try:\n",
    "                        lines = glossa.splitlines()\n",
    "                        for i in range(len(lines)):\n",
    "                            line = lines[i]\n",
    "\n",
    "                            if line == \"\":\n",
    "                                # etim_flag = False\n",
    "                                # pron_flag = False\n",
    "                                # sill_flag = False\n",
    "                                continue\n",
    "\n",
    "                            if pron_flag:\n",
    "                                pron_flag = get_ipa(line, lemma)\n",
    "                                if pron_flag:\n",
    "                                    continue # di ipa possono essercene più di una\n",
    "\n",
    "                            if sill_flag:\n",
    "                                found = get_sill(line, lemma)\n",
    "                                if found:\n",
    "                                    sill_flag = False\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    sill_flag = False\n",
    "                            \n",
    "                            if etim_flag:\n",
    "                                if noetim_check(line):\n",
    "                                    etim_flag = False\n",
    "                                    continue\n",
    "                                if line[0] == \"#\" or line[0] == \"*\" or line[0] == \":\":\n",
    "                                    get_etim(line, lemma)\n",
    "                                    continue\n",
    "                                else:\n",
    "                                    get_etim(line, lemma)\n",
    "                                    etim_flag = False                              \n",
    "                                    continue \n",
    "\n",
    "                            if line.find(\"{{Vedi|\") != -1:\n",
    "                                continue\n",
    "                            if line[0] == \"[\": #immagini\n",
    "                                continue\n",
    "\n",
    "                            if line[0] == \"=\":\n",
    "                                lang, lang_found = lang_check(line, lemma)\n",
    "                                if lang == 0: # se la line inizia con \"=\" ma non ha informazioni sulla lingua \n",
    "                                    continue\n",
    "                                if lang != \"it\":\n",
    "                                    break\n",
    "                                if lang_found:\n",
    "                                    continue\n",
    "                            \n",
    "                            if not lang_found:\n",
    "                                continue\n",
    "                            \n",
    "                            if not unk_pos_flag: # di default si mette sempre una pos unk\n",
    "                                current_pos = unk_pos(lemma)\n",
    "                                unk_pos_flag = True\n",
    "                            \n",
    "                            pos = check_pos(lemma, line, i_pos, current_pos)\n",
    "                            if current_pos != pos:\n",
    "                                etim_flag = False\n",
    "                                i_pos +=1\n",
    "                                current_pos = pos\n",
    "                                continue\n",
    "\n",
    "                            pron_flag = pron_check(line)\n",
    "                            if pron_flag:\n",
    "                                continue\n",
    "                            \n",
    "                            sill_flag = sill_check(line)\n",
    "                            if sill_flag:\n",
    "                                continue # se trovo il token della sill allora passo alla iter successiva\n",
    "                            \n",
    "                            if morpho_check(line, lemma, current_pos):\n",
    "                                continue\n",
    "\n",
    "                            etim_flag = etim_check(line)\n",
    "                            if etim_flag:\n",
    "                                continue\n",
    "\n",
    "                            if line[0] == \"#\": # glossa\n",
    "                                if line[-1] == \":\": # introduce elenco\n",
    "                                    elenco_flag = True\n",
    "                                try:\n",
    "                                    if line[1] == \"*\" and not elenco_flag: # esempio\n",
    "                                        continue\n",
    "                                except IndexError:\n",
    "                                    continue # linea[1:] è vuota\n",
    "                                glossa_check(line, lemma, current_pos)\n",
    "                            else:\n",
    "                                elenco_flag = False # se dopo un elenco puntato ho una lista di esempi?\n",
    "                                                \n",
    "                    except Exception as e:\n",
    "                        print(\"ERRORE al lemma\", lemma)\n",
    "                        raise\n",
    "\n",
    "    del context\n",
    "\n",
    "# albicocca etim\n",
    "# andare etim list\n",
    "# asili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing XML: 0 elements [00:00, ? elements/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing XML: 19300866 elements [03:03, 105272.09 elements/s]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369056, 562905, 193849)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_found_lemmas = [x for x in all_lemmas if x not in parsed_dict]\n",
    "len(parsed_dict), len(all_lemmas), len(not_found_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meta': {'ipa': ['anˈda.re'], 'sill': ['an', 'dà', 're'], 'etim': 'Devoto/Oli: dal Latino ambitare, forma intensiva di ambire,  andare in giro'}, 'meanings': {'verb_0': {'morpho': '', 'glossa': \"muoversi da un luogo verso un altro luogo\\npartire\\nessere destinato a esser messo in una data posizione\\ndover essere (con un participio passato), dover subire una certa azione (usato prevalentemente alla terza persona, singolare o plurale)\\nnecessità fisiche naturali, in particolare con riferimento all'evacuazione\"}, 'sost_1': {'morpho': 'm inv.', 'glossa': \"incedere, modo di incedere\\npassaggio del tempo\\nespressione che indica il continuo realizzarsi del tempo, in particolare nella consapevolezza precedente oppure successiva ad un'azione o a qualcosa che deve succedere oppure appena accaduto\"}}}\n"
     ]
    }
   ],
   "source": [
    "print(parsed_dict[\"andare\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3864"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unknown = []\n",
    "for k in parsed_dict:\n",
    "    one_def = False\n",
    "    try:\n",
    "        for m in parsed_dict[k][\"meanings\"]:\n",
    "            if parsed_dict[k][\"meanings\"][m][\"glossa\"] != \"\":\n",
    "                one_def = True\n",
    "            \n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if one_def == False:\n",
    "        unknown.append(k)\n",
    "\n",
    "len(unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rosso vino',\n",
       " 'Urano',\n",
       " 'Plutone',\n",
       " 'brahmanico',\n",
       " 'Belgio',\n",
       " 'ratto',\n",
       " 'Antartide',\n",
       " 'Antille Olandesi',\n",
       " 'Arabia Saudita',\n",
       " 'Ratisbona',\n",
       " 'Zurigo',\n",
       " 'arancio giallastro',\n",
       " 'allochero',\n",
       " 'bisdrucciolo',\n",
       " 'parossitono',\n",
       " 'Lugano',\n",
       " 'maratto',\n",
       " 'verde oliva',\n",
       " 'basso sassone',\n",
       " 'creative',\n",
       " 'singalese',\n",
       " 'sbucciapatate',\n",
       " 'CPA',\n",
       " 'gujarati',\n",
       " 'moksha',\n",
       " 'moxel',\n",
       " 'erzyra',\n",
       " 'khmer',\n",
       " 'bacino idrico',\n",
       " 'cinese semplificato',\n",
       " 'penna a sfera',\n",
       " 'Aristotele',\n",
       " 'buio pesto',\n",
       " 'alto tedesco antico',\n",
       " 'Meno',\n",
       " 'Iran',\n",
       " 'bislama',\n",
       " 'nome proprio',\n",
       " 'anellini',\n",
       " 'spina dorsale',\n",
       " 'aymara',\n",
       " 'capa',\n",
       " 'fuggi fuggi',\n",
       " 'gamma',\n",
       " 'capone',\n",
       " 'paralinguaggio',\n",
       " 'fisica quantica',\n",
       " 'strutto',\n",
       " 'cipollina',\n",
       " 'cece',\n",
       " 'tostino',\n",
       " 'magnetismo terrestre',\n",
       " 'beige verdastro',\n",
       " 'giallo sabbia',\n",
       " 'giallo segnale',\n",
       " 'giallo miele',\n",
       " 'giallo narciso',\n",
       " 'beige grigiastro',\n",
       " 'alifante',\n",
       " 'asiago',\n",
       " 'assamese',\n",
       " 'girl',\n",
       " 'struttura operativa',\n",
       " 'chiodo di garofano',\n",
       " 'scapolone',\n",
       " 'stella di Natale',\n",
       " 'na',\n",
       " 'bacile',\n",
       " 'Regno Unito',\n",
       " 'Estonia',\n",
       " 'cipollaio',\n",
       " 'pullo',\n",
       " 'topa',\n",
       " 'giuggiola',\n",
       " 'menna',\n",
       " 'pulli',\n",
       " 'Gujarat',\n",
       " \"non c'è di che\",\n",
       " 'buone feste',\n",
       " 'ad',\n",
       " 'guar',\n",
       " 'limburghese',\n",
       " 'friulano',\n",
       " 'grazie, altrettanto',\n",
       " 'mi scusi',\n",
       " 'per favore',\n",
       " 'pitcairnese',\n",
       " 'tassofoni',\n",
       " 'Bangkok',\n",
       " 'Colombo',\n",
       " 'catastrofe alluvionale',\n",
       " 'Indonesia',\n",
       " 'atletica leggera',\n",
       " 'primo soccorso',\n",
       " 'buon compleanno',\n",
       " 'Olanda',\n",
       " 'anticaustica',\n",
       " 'spirale di Archimede',\n",
       " 'curva algebrica',\n",
       " 'alisoide',\n",
       " 'curva anallagmatica',\n",
       " 'Liechtenstein',\n",
       " 'dentice reale',\n",
       " 'abbreviate',\n",
       " 'abominate',\n",
       " 'AC',\n",
       " 'ade',\n",
       " 'and',\n",
       " 'angina',\n",
       " 'desk',\n",
       " 'apposite',\n",
       " 'arbitrate',\n",
       " 'half',\n",
       " 'arme',\n",
       " 'assist',\n",
       " 'he',\n",
       " 'band',\n",
       " 'basket',\n",
       " 'hobby',\n",
       " 'diminutive',\n",
       " 'intact',\n",
       " 'disgusting',\n",
       " 'invalidate',\n",
       " 'disoriented',\n",
       " 'item',\n",
       " 'jack',\n",
       " 'big',\n",
       " 'knock-out',\n",
       " 'boring',\n",
       " 'break',\n",
       " 'budget',\n",
       " 'citrino',\n",
       " 'contralto',\n",
       " 'celia',\n",
       " 'Anversa',\n",
       " 'denunzia',\n",
       " 'posto che',\n",
       " 'Cenacolo',\n",
       " 'estorcere',\n",
       " 'sfiatato',\n",
       " 'caterpillar',\n",
       " 'concrete',\n",
       " 'convention',\n",
       " 'culture',\n",
       " 'decanter',\n",
       " 'dissolve',\n",
       " 'editorial',\n",
       " 'eminent',\n",
       " 'equity',\n",
       " 'escort',\n",
       " 'ethereal',\n",
       " 'famous',\n",
       " 'free',\n",
       " 'gang',\n",
       " 'gap',\n",
       " 'gate',\n",
       " 'green',\n",
       " 'lighthouse',\n",
       " 'loath',\n",
       " 'loathsome',\n",
       " 'location',\n",
       " 'lustre',\n",
       " 'Machiavellian',\n",
       " 'magazine',\n",
       " 'match',\n",
       " 'metal',\n",
       " 'mischievous',\n",
       " 'mission',\n",
       " 'mm',\n",
       " 'monastery',\n",
       " 'muscle',\n",
       " 'must',\n",
       " 'ossetico',\n",
       " 'carta legale',\n",
       " 'dorare',\n",
       " 'afa',\n",
       " 'ava',\n",
       " 'baffa',\n",
       " 'alo',\n",
       " 'pippa',\n",
       " 'birba',\n",
       " 'damaschino',\n",
       " 'gravida',\n",
       " 'biscuocere',\n",
       " 'kinyarwanda',\n",
       " 'Venerdì Santo',\n",
       " 'buona Pasqua',\n",
       " 'Domenica delle Palme',\n",
       " 'uovo di Pasqua',\n",
       " 'carnera',\n",
       " 'casina',\n",
       " 'cicerchia',\n",
       " 'Friuli',\n",
       " 'argento vivo',\n",
       " 'ananassa',\n",
       " 'hopi',\n",
       " 'sovranaturale',\n",
       " 'crocifissione',\n",
       " 'Baphomet',\n",
       " 'UTC',\n",
       " 'scala minore naturale',\n",
       " 'Germanio',\n",
       " 'pacca',\n",
       " 'turoniano',\n",
       " 'messiniano',\n",
       " 'sanscrito',\n",
       " 'Salomone',\n",
       " 'fonte battesimale',\n",
       " 'confessionale',\n",
       " 'in altre parole',\n",
       " 'IGP',\n",
       " 'indicazione geografica protetta',\n",
       " 'e',\n",
       " 'erosivo',\n",
       " 'grosso modo',\n",
       " 'ciucca',\n",
       " 'Città del Vaticano',\n",
       " 'edit',\n",
       " 'preterizione',\n",
       " 'mitologia greca',\n",
       " 'ferza',\n",
       " 'conventuale',\n",
       " 'monacarsi',\n",
       " 'CIC',\n",
       " 'consultorio familiare',\n",
       " 'ISCLa',\n",
       " 'human relations',\n",
       " 'relazioni industriali',\n",
       " 'Ognissanti',\n",
       " 'mirandese',\n",
       " 'guida turistica',\n",
       " 'Spartaco',\n",
       " 'Valsesia',\n",
       " 'mo',\n",
       " 'enarmonia',\n",
       " 'irco',\n",
       " 'giallo oro',\n",
       " 'giallo polenta',\n",
       " 'beige marrone',\n",
       " 'giallo limone',\n",
       " 'bianco perla',\n",
       " 'avorio chiaro',\n",
       " 'giallo zolfo',\n",
       " 'giallo zinco',\n",
       " 'giallo olivastro',\n",
       " 'giallo navone',\n",
       " 'giallo traffico',\n",
       " 'giallo ocra',\n",
       " 'giallo curry',\n",
       " 'giallo scopa',\n",
       " 'giallo dahlien',\n",
       " 'arancio rossastro',\n",
       " 'arancio sanguigno',\n",
       " 'arancio traffico',\n",
       " 'arancio segnale',\n",
       " 'arancio profondo',\n",
       " 'arancio salmone',\n",
       " 'rosso segnale',\n",
       " 'rosso rubino',\n",
       " 'rosso porpora',\n",
       " 'rosso nerastro',\n",
       " 'rosso ossido',\n",
       " 'rosso marrone',\n",
       " 'rosso beige',\n",
       " 'rosso pomodoro',\n",
       " 'rosa antico',\n",
       " 'rosa chiaro',\n",
       " 'rosso corallo',\n",
       " 'rosso fragola',\n",
       " 'rosso traffico',\n",
       " 'rosso salmone',\n",
       " 'rosso brillante',\n",
       " 'rosso lampone',\n",
       " 'rosso oriente',\n",
       " 'lilla rossastro',\n",
       " 'viola rossastro',\n",
       " 'viola erica',\n",
       " 'porpora violetto',\n",
       " 'violetto segnale',\n",
       " 'violetto pastello',\n",
       " 'blu violaceo',\n",
       " 'blu verdastro',\n",
       " 'blu nerastro',\n",
       " 'blu segnale',\n",
       " 'blu grigiastro',\n",
       " 'blu azzurro',\n",
       " 'blu genziana',\n",
       " 'blu acciaio',\n",
       " 'blu luce',\n",
       " 'blu cobalto',\n",
       " 'blu colomba',\n",
       " 'blu cielo',\n",
       " 'blu traffico',\n",
       " 'blu turchese',\n",
       " 'blu notte',\n",
       " 'blu distante',\n",
       " 'blu pastello',\n",
       " 'verde patina',\n",
       " 'verde bluastro',\n",
       " 'verde bottiglia',\n",
       " 'verde brunastro',\n",
       " 'verde abete',\n",
       " 'verde erba',\n",
       " 'verde reseda',\n",
       " 'verde nerastro',\n",
       " 'verde canna',\n",
       " 'oliva giallastro',\n",
       " 'verde maggio',\n",
       " 'verde giallastro',\n",
       " 'verde biancastro',\n",
       " 'verde cromo',\n",
       " 'oliva brunastro',\n",
       " 'verde traffico',\n",
       " 'verde felce',\n",
       " 'verde chiaro',\n",
       " 'verde pino',\n",
       " 'verde menta',\n",
       " 'verde segnale',\n",
       " 'turchese menta',\n",
       " 'turchese pastello',\n",
       " 'grigio argento',\n",
       " 'grigio olivastro',\n",
       " 'grigio muschio',\n",
       " 'grigio segnale',\n",
       " 'grigio topo',\n",
       " 'grigio beige',\n",
       " 'grigio kaki',\n",
       " 'grigio verdastro',\n",
       " 'grigio tenda',\n",
       " 'grigio ferro',\n",
       " 'grigio basalto',\n",
       " 'grigio brunastro',\n",
       " 'grigio ardesia',\n",
       " 'grigio antracite',\n",
       " 'grigio nerastro',\n",
       " 'grigio ombra',\n",
       " 'grigio calcestruzzo',\n",
       " 'grigio grafite',\n",
       " 'grigio granito',\n",
       " 'grigio pietra',\n",
       " 'grigio bluastro',\n",
       " 'grigio ghiaia',\n",
       " 'grigio cemento',\n",
       " 'grigio giallastro',\n",
       " 'grigio luce',\n",
       " 'grigio platino',\n",
       " 'grigio agata',\n",
       " 'grigio quarzo',\n",
       " 'grigio finestra',\n",
       " 'grigio traffico a',\n",
       " 'grigio traffico b',\n",
       " 'grigio seta',\n",
       " 'grigio topo perlato',\n",
       " 'marrone verdastro',\n",
       " 'marrone ocra',\n",
       " 'marrone segnale',\n",
       " 'marrone fango',\n",
       " 'marrone rame',\n",
       " 'marrone capriolo',\n",
       " 'marrone noce',\n",
       " 'marrone rossiccio',\n",
       " 'marrone seppia',\n",
       " 'marrone castagna',\n",
       " 'marrone mogano',\n",
       " 'marrone cioccolata',\n",
       " 'marrone grigiastro',\n",
       " 'marrone nerastro',\n",
       " 'marrone terra',\n",
       " 'bianco crema',\n",
       " 'bianco grigiastro',\n",
       " 'bianco segnale',\n",
       " 'nero segnale',\n",
       " 'nero intenso',\n",
       " 'nero grafite',\n",
       " 'bianco traffico',\n",
       " 'nero traffico',\n",
       " 'bianco papiro',\n",
       " 'opercolo',\n",
       " 'FEOGA',\n",
       " 'jiddisch',\n",
       " 'sentì',\n",
       " 'acido gluconico',\n",
       " 'acido succinico',\n",
       " 'acido tartarico',\n",
       " 'alcool etilico',\n",
       " 'alzavino',\n",
       " 'analisi sensoriale',\n",
       " 'anidride carbonica',\n",
       " 'archetti del vino',\n",
       " 'bentonite',\n",
       " 'brenta',\n",
       " 'colmatura',\n",
       " 'DOC',\n",
       " 'decantazione',\n",
       " 'follatura',\n",
       " 'gabbietta',\n",
       " 'sgrondatura',\n",
       " 'spillatura',\n",
       " 'vinacciolo',\n",
       " 'vinificatore',\n",
       " 'vinificazione',\n",
       " 'zuccheraggio',\n",
       " 'noce moscata',\n",
       " 'fuoco artificiale',\n",
       " 'ambedue',\n",
       " 'pienezza',\n",
       " 'lastra',\n",
       " 'stralpo',\n",
       " 'vitame',\n",
       " 'viteria',\n",
       " 'viticoltura',\n",
       " 'Tucidide',\n",
       " 'Diodoro',\n",
       " 'Federico',\n",
       " 'scenograficamente',\n",
       " 'padiglione auricolare',\n",
       " 'stile di vita',\n",
       " 'ovoidale',\n",
       " 'Giacinto',\n",
       " 'loggetta',\n",
       " 'monofora',\n",
       " 'apice polmonare',\n",
       " 'Susanna',\n",
       " 'Assuero',\n",
       " 'Olofene',\n",
       " 'roccaforti',\n",
       " 'possanza',\n",
       " 'Nestore',\n",
       " 'Assunzione',\n",
       " 'special',\n",
       " 'tell',\n",
       " 'integrista',\n",
       " 'EZLN',\n",
       " 'Chiapas',\n",
       " 'como',\n",
       " 'etica professionale',\n",
       " 'marron',\n",
       " 'apostatare',\n",
       " 'neckerchief',\n",
       " 'network',\n",
       " 'not',\n",
       " 'omelette',\n",
       " 'piano',\n",
       " 'plaquette',\n",
       " 'play',\n",
       " 'pointer',\n",
       " 'poise',\n",
       " 'pot',\n",
       " 'puff',\n",
       " 'rape',\n",
       " 'rapport',\n",
       " 'reception',\n",
       " 'recital',\n",
       " 'regularly',\n",
       " 'rejoicing',\n",
       " 'rustic',\n",
       " 'Uruk',\n",
       " 'saloon',\n",
       " 'saving',\n",
       " 'scoop',\n",
       " 'se',\n",
       " 'seasoned',\n",
       " 'smash',\n",
       " 'snort',\n",
       " 'sound',\n",
       " 'speech',\n",
       " 'steep',\n",
       " 'tape',\n",
       " 'target',\n",
       " 'timer',\n",
       " 'to',\n",
       " 'tour',\n",
       " 'TV',\n",
       " 'unscrupulous',\n",
       " 'unusual',\n",
       " 'visible',\n",
       " 'warrant',\n",
       " 'weakly',\n",
       " 'zestfulness',\n",
       " 'conscienza',\n",
       " 'accordo a latere',\n",
       " 'caotici',\n",
       " 'caotiche',\n",
       " 'ritener',\n",
       " 'contratto di vendita',\n",
       " 'incondizionatamente',\n",
       " 'Antalya',\n",
       " 'Zenon',\n",
       " 'Efeso',\n",
       " 'Pergamo',\n",
       " 'Perga',\n",
       " 'Seleucidi',\n",
       " 'mahjong',\n",
       " 'gastrodinia',\n",
       " 'poter',\n",
       " 'STA',\n",
       " 'ok',\n",
       " 'Bologna',\n",
       " 'Bombay',\n",
       " 'bungalow',\n",
       " 'Acre',\n",
       " 'Stoccarda',\n",
       " 'linguaggio mimico',\n",
       " 'cudera',\n",
       " 'cunetta',\n",
       " 'diu',\n",
       " 'facundia',\n",
       " 'gamia',\n",
       " 'guttera',\n",
       " 'infra',\n",
       " 'lanzafina',\n",
       " 'li',\n",
       " 'mala',\n",
       " 'casciubico',\n",
       " 'cherokee',\n",
       " 'rutherford',\n",
       " 'Sassonia-Anhalt',\n",
       " 'Brääklem',\n",
       " 'Kairem',\n",
       " 'alle',\n",
       " 'allo',\n",
       " 'tempo di Planck',\n",
       " 'Nuoro',\n",
       " 'sarchiapone',\n",
       " 'Cracovia',\n",
       " 'lady',\n",
       " 'provenienti',\n",
       " 'Altare',\n",
       " 'Basilicata',\n",
       " 'CEE',\n",
       " 'Adelina',\n",
       " 'Alida',\n",
       " 'Alighiero',\n",
       " 'Amelia',\n",
       " 'Azzurra',\n",
       " 'Armindo',\n",
       " 'Arnaldo',\n",
       " 'Arnoldo',\n",
       " 'Beatrice',\n",
       " 'Benedetta',\n",
       " 'Benedetto',\n",
       " 'Bruna',\n",
       " 'Berta',\n",
       " 'Berto',\n",
       " 'Camilla',\n",
       " 'Carla',\n",
       " 'Caterina',\n",
       " 'Cesara',\n",
       " 'Cristiana',\n",
       " 'Daniela',\n",
       " 'Daria',\n",
       " 'Dora',\n",
       " 'Dorotea',\n",
       " 'Cristiano',\n",
       " 'Cipriano',\n",
       " 'Cesare',\n",
       " 'Como',\n",
       " 'Cremona',\n",
       " 'Lecco',\n",
       " 'Lodi',\n",
       " 'Mantova',\n",
       " 'Pavia',\n",
       " 'Sondrio',\n",
       " 'Verbania',\n",
       " 'Biella',\n",
       " 'Cuneo',\n",
       " 'Vercelli',\n",
       " 'Imperia',\n",
       " 'La Spezia',\n",
       " 'Savona',\n",
       " 'Rovigo',\n",
       " 'Verona',\n",
       " 'Vicenza',\n",
       " 'Trieste',\n",
       " 'Gorizia',\n",
       " 'Pordenone',\n",
       " 'Udine',\n",
       " 'Ferrara',\n",
       " 'Modena',\n",
       " \"Reggio nell'Emilia\",\n",
       " 'Arezzo',\n",
       " 'Grosseto',\n",
       " 'Lucca',\n",
       " 'Pisa',\n",
       " 'Pistoia',\n",
       " 'Siena',\n",
       " 'Massa',\n",
       " 'Terni',\n",
       " 'Perugia',\n",
       " 'Pesaro',\n",
       " 'Ascoli Piceno',\n",
       " 'Macerata',\n",
       " 'Rieti',\n",
       " 'Viterbo',\n",
       " 'Pescara',\n",
       " 'Isernia',\n",
       " 'Taranto',\n",
       " 'Foggia',\n",
       " 'Barletta',\n",
       " 'Matera',\n",
       " 'Potenza',\n",
       " 'Cagliari',\n",
       " 'Enna',\n",
       " 'Messina',\n",
       " 'Oristano',\n",
       " 'Ogliastra',\n",
       " 'Carbonia',\n",
       " 'Sanluri',\n",
       " 'Tempio Pausania',\n",
       " 'Catanzaro',\n",
       " 'Cosenza',\n",
       " 'Crotone',\n",
       " 'Reggio Calabria',\n",
       " 'Zagabria',\n",
       " 'Eduardo',\n",
       " 'Elena',\n",
       " 'Emilia',\n",
       " 'Emiliano',\n",
       " 'Emilio',\n",
       " 'Enrica',\n",
       " 'Enrico',\n",
       " 'Ermenegilda',\n",
       " 'Ermenegildo',\n",
       " 'Ernerio',\n",
       " 'Ernesto',\n",
       " 'Eros',\n",
       " 'Ferdinando',\n",
       " 'Fulvio',\n",
       " 'Fernando',\n",
       " 'Fabiana',\n",
       " 'Fabiola',\n",
       " 'Ferdinanda',\n",
       " 'Fernanda',\n",
       " 'Fiorella',\n",
       " 'Fulvia',\n",
       " 'Giuliana',\n",
       " 'Giuseppa',\n",
       " 'Gennaro',\n",
       " 'Gianluca',\n",
       " 'Gianpaolo',\n",
       " 'Giuliano',\n",
       " 'Irma',\n",
       " 'Luana',\n",
       " 'Luigia',\n",
       " 'Luisa',\n",
       " 'Italo',\n",
       " 'Massimiliano',\n",
       " 'Mattia',\n",
       " 'Nazzareno',\n",
       " 'Norberto',\n",
       " 'Otello',\n",
       " 'Maria',\n",
       " 'Maurizia',\n",
       " 'Patrizio',\n",
       " 'Quarto',\n",
       " 'Rosalino',\n",
       " 'Rossano',\n",
       " 'Secondo',\n",
       " 'Sergio',\n",
       " 'Serse',\n",
       " 'Settimo',\n",
       " 'Sesto',\n",
       " 'Settimio',\n",
       " 'Silvestro',\n",
       " 'Silvio',\n",
       " 'Patrizia',\n",
       " 'Raffaela',\n",
       " 'Sabrina',\n",
       " 'Tazio',\n",
       " 'Tarcisio',\n",
       " 'Ultimo',\n",
       " 'Valentino',\n",
       " 'Tosca',\n",
       " 'Vittoria',\n",
       " 'Loris',\n",
       " 'Oceano Atlantico',\n",
       " 'pioviggine',\n",
       " 'piovigginare',\n",
       " 'sbattezzo',\n",
       " 'Tessa',\n",
       " 'riciao',\n",
       " 'ladino fassano',\n",
       " 'academia',\n",
       " \"po'\",\n",
       " 'MPLS',\n",
       " 'covacciolo',\n",
       " 'frogia',\n",
       " 'salumaio',\n",
       " 'Medolla',\n",
       " 'notte di Natale',\n",
       " 'tesauro',\n",
       " 'mensiocronologia',\n",
       " 'bimestrale',\n",
       " 'smarino',\n",
       " 'allupare',\n",
       " 'sinechismo',\n",
       " 'cocuncio',\n",
       " 'sciabordito',\n",
       " 'panenteismo',\n",
       " 'planetarie',\n",
       " 'guidone',\n",
       " 'cercatore',\n",
       " 'dock',\n",
       " 'asciugatoio',\n",
       " 'ferro da stiro',\n",
       " 'immondizie',\n",
       " 'pirofila',\n",
       " 'presina',\n",
       " 'secchio delle immondizie',\n",
       " 'stipetto',\n",
       " 'Alkes',\n",
       " 'sci di fondo',\n",
       " 'sci alpino',\n",
       " 'danza su ghiaccio',\n",
       " 'autodimostrativo',\n",
       " 'spirale archimedea',\n",
       " 'San Paolo',\n",
       " 'paratattica',\n",
       " 'figura retorica',\n",
       " 'afferenza',\n",
       " 'esc',\n",
       " 'microtuner',\n",
       " 'spettrografo di massa',\n",
       " 'DL',\n",
       " 'giostratore',\n",
       " 'giumella',\n",
       " 'pispiglìo',\n",
       " 'templari',\n",
       " 'risonanza elettrica',\n",
       " 'ludobus',\n",
       " 'nome comune',\n",
       " 'consigliabile',\n",
       " 'monitoring',\n",
       " 'monitoraggio',\n",
       " 'specolazione',\n",
       " 'Gothmog',\n",
       " 'ceppa',\n",
       " 'moldavo',\n",
       " 'leccaciuffi',\n",
       " 'autodiagnostica',\n",
       " 'musicale',\n",
       " 'reverso',\n",
       " 'stiacciata',\n",
       " 'vasetto',\n",
       " 'incomodato',\n",
       " 'tarlucco',\n",
       " 'mimi',\n",
       " 'nel termine stabilito',\n",
       " 'Elisa',\n",
       " 'scalppiccio',\n",
       " 'stilato',\n",
       " 'offuscata',\n",
       " 'SIULP',\n",
       " 'ASNOSS',\n",
       " 'Wheatwin1',\n",
       " 'diaconessa',\n",
       " 'clown dottore',\n",
       " 'bel',\n",
       " 'blackfoot',\n",
       " 'malayalam',\n",
       " 'vallone',\n",
       " 'Farnesina',\n",
       " 'guizzante',\n",
       " 'società a partecipazione pubblica',\n",
       " 'ospitato',\n",
       " 'cromata',\n",
       " 'trasgressivo',\n",
       " 'estratti vegetali',\n",
       " 'trascendentale',\n",
       " 'asseguire',\n",
       " 'dottore pagliaccio',\n",
       " 'cartoonist',\n",
       " 'sostegno psicologico',\n",
       " 'etologa',\n",
       " 'falangine',\n",
       " 'caciotta',\n",
       " 'cartòfilo',\n",
       " 'sbagliare',\n",
       " 'controintuitivo',\n",
       " 'giava',\n",
       " 'ostessa',\n",
       " 'degni',\n",
       " 'botto',\n",
       " 'axenica',\n",
       " 'svestito',\n",
       " 'prozia',\n",
       " 'm',\n",
       " 'radiorilevatore',\n",
       " 'ademprivio',\n",
       " 'Teresa',\n",
       " 'Fiore',\n",
       " 'Adriana',\n",
       " 'Acillino',\n",
       " 'Adone',\n",
       " 'Agostino',\n",
       " 'Aido',\n",
       " 'Alberico',\n",
       " 'Albio',\n",
       " 'Albo',\n",
       " 'Alcino',\n",
       " 'Alciso',\n",
       " 'Alderico',\n",
       " 'Aldobrando',\n",
       " 'Alduino',\n",
       " 'Aleardo',\n",
       " 'Alfiero',\n",
       " 'Alghisio',\n",
       " 'Algisio',\n",
       " 'Algiso',\n",
       " 'Alicio',\n",
       " 'Alideo',\n",
       " 'Alido',\n",
       " 'Alisio',\n",
       " 'Aliso',\n",
       " 'Aliviero',\n",
       " 'Allegrino',\n",
       " 'Allegro',\n",
       " 'Almerino',\n",
       " 'Alteo',\n",
       " 'Altero',\n",
       " 'Alvezio',\n",
       " 'Amalio',\n",
       " 'Amandino',\n",
       " 'Amando',\n",
       " 'Amato',\n",
       " 'Amelio',\n",
       " 'Amos',\n",
       " 'Ampelio',\n",
       " 'Anastasio',\n",
       " 'Anatolio',\n",
       " 'Angelico',\n",
       " 'Anito',\n",
       " 'Annetto',\n",
       " 'Annibale',\n",
       " 'Annico',\n",
       " 'Annino',\n",
       " 'Annito',\n",
       " 'Annuccio',\n",
       " 'Annunciato',\n",
       " 'Annuncio',\n",
       " 'Annunziato',\n",
       " 'Annunzio',\n",
       " 'Antigono',\n",
       " 'Antimo',\n",
       " 'Antino',\n",
       " 'Apollonio',\n",
       " 'Appio',\n",
       " 'Aquilino',\n",
       " 'Archippo',\n",
       " 'Arcisio',\n",
       " 'Arciso',\n",
       " 'Ardito',\n",
       " 'Argentino',\n",
       " 'Argento',\n",
       " 'Argeo',\n",
       " 'Argio',\n",
       " 'Arianno',\n",
       " 'Aristide',\n",
       " 'Aristofane',\n",
       " 'Armando',\n",
       " 'Armelindo',\n",
       " 'Armellino',\n",
       " 'Armello',\n",
       " 'Arminio',\n",
       " 'Aroldo',\n",
       " 'Aronzio',\n",
       " 'Arrigo',\n",
       " 'Arsacio',\n",
       " 'Arsilio',\n",
       " 'Artemio',\n",
       " 'Arturo',\n",
       " 'Aspasio',\n",
       " 'Assuntino',\n",
       " 'Assunto',\n",
       " 'Atos',\n",
       " 'Attila',\n",
       " 'Attilio',\n",
       " 'Augusto',\n",
       " 'Aureo',\n",
       " 'Aurino',\n",
       " 'Auro',\n",
       " 'Avelino',\n",
       " 'Avelio',\n",
       " 'Averio',\n",
       " 'Aviero',\n",
       " 'Azaria',\n",
       " 'Azzo',\n",
       " 'Azzurrino',\n",
       " 'Azzurro',\n",
       " 'Balderico',\n",
       " 'Baldomero',\n",
       " 'Baldovino',\n",
       " 'Balsamo',\n",
       " 'Barachisio',\n",
       " 'Barbarigo',\n",
       " 'Barbarino',\n",
       " 'Barbato',\n",
       " 'Barbaziano',\n",
       " 'Barberino',\n",
       " 'Bardomiano',\n",
       " 'Barlaam',\n",
       " 'Barsaba',\n",
       " 'Barsanufio',\n",
       " 'Barsimeo',\n",
       " 'Bartolomeo',\n",
       " 'Basiliano',\n",
       " 'Basilide',\n",
       " 'Basilisco',\n",
       " 'Basolo',\n",
       " 'Basso',\n",
       " 'Baudelio',\n",
       " 'Baudino',\n",
       " 'Baudolino',\n",
       " 'Bavone',\n",
       " 'Beano',\n",
       " 'Beato',\n",
       " 'Beco',\n",
       " 'Beda',\n",
       " 'Bellino',\n",
       " 'Bello',\n",
       " 'Beltramo',\n",
       " 'Bencivenni',\n",
       " 'Beneno',\n",
       " 'Benigno',\n",
       " 'Benildo',\n",
       " 'Beno',\n",
       " 'Benvenuto',\n",
       " 'Berardo',\n",
       " 'Bercario',\n",
       " 'Berengario',\n",
       " 'Bernabo',\n",
       " 'Bernardo',\n",
       " 'Bernone',\n",
       " 'Bernulfo',\n",
       " 'Bernwardo',\n",
       " 'Beronico',\n",
       " 'Bertolfo',\n",
       " 'Bertrando',\n",
       " 'Bessarione',\n",
       " 'Betta',\n",
       " 'Bettino',\n",
       " 'Betto',\n",
       " 'Biancardo',\n",
       " 'Bianchino',\n",
       " 'Bianco',\n",
       " 'Bianore',\n",
       " 'Bibbiano',\n",
       " 'Bibiano',\n",
       " 'Biblide',\n",
       " 'Bindo',\n",
       " 'Biondo',\n",
       " 'Birillo',\n",
       " 'Blandina',\n",
       " 'Blando',\n",
       " 'Blitmondo',\n",
       " 'Bobuleno',\n",
       " 'Boetiano',\n",
       " 'Boezio',\n",
       " 'Bonagiunta',\n",
       " 'Bonaldo',\n",
       " 'Bonaventura',\n",
       " 'Bonavita',\n",
       " 'Bonello',\n",
       " 'Bonetto',\n",
       " 'Bonfiglio',\n",
       " 'Bonifacio',\n",
       " 'Bonito',\n",
       " 'Bono',\n",
       " 'Bononio',\n",
       " 'Bonoso',\n",
       " 'Bosone',\n",
       " 'Bovo',\n",
       " 'Brancaleone',\n",
       " 'Brandano',\n",
       " 'Braulio',\n",
       " 'Bretannione',\n",
       " 'Brigido',\n",
       " 'Brizio',\n",
       " 'Broccardo',\n",
       " 'Brunildo',\n",
       " 'Burcardo',\n",
       " 'Cabirio',\n",
       " 'Cafiero',\n",
       " 'Calcedonio',\n",
       " 'Callisto',\n",
       " 'Candeloro',\n",
       " 'Canzio',\n",
       " 'Carino',\n",
       " 'Carmelindo',\n",
       " 'Carmelino',\n",
       " 'Carmelio',\n",
       " 'Carmelito',\n",
       " 'Carmenio',\n",
       " 'Carminio',\n",
       " 'Carmino',\n",
       " 'Carminuccio',\n",
       " 'Caro',\n",
       " 'Carolino',\n",
       " 'Carolo',\n",
       " 'Cartesio',\n",
       " ...]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_etim  = []\n",
    "for k in parsed_dict:\n",
    "    if parsed_dict[k][\"meta\"][\"etim\"] == \"\":\n",
    "        no_etim.append(k)\n",
    "print(len(no_etim))\n",
    "no_etim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"it-dictionary.json\", \"w\") as f:\n",
    "    json.dump(parsed_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
